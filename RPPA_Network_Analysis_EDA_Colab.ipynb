{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RPPA Network Analysis - Exploratory data analysis workflow\n",
        "### Requires:\n",
        "Cytoscape 3.10.0 or later\n",
        "\n",
        "Jupyter notebook v2023.4.1011241018 or later\n",
        "\n",
        "Python 3.10.9 or later\n",
        "\n",
        "Python packages:\n",
        "    \n",
        "    py4cytoscape\n",
        "    pandas\n",
        "    numpy\n",
        "    scipy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Start Cytoscape on your computer\n",
        "## Step 2: Run code blocks below in order\n",
        "### 2.A: Import Python packages and connect to Cytoscape (Google Colab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHAwpQEK0f_m"
      },
      "outputs": [],
      "source": [
        "# Install and import required packages\n",
        "%%capture\n",
        "!pip3 install py4cytoscape\n",
        "!pip3 install numpy\n",
        "!pip3 install scipy\n",
        "import IPython\n",
        "import py4cytoscape as p4c\n",
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy.random import seed\n",
        "from scipy.stats import shapiro\n",
        "from scipy.stats import stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "01yejuZkS-7P",
        "outputId": "0c7b8e6a-2fcc-4def-d904-63e5014db3b6"
      },
      "outputs": [],
      "source": [
        "# Build connection between the cloud jupyter notebookand local Cytoscape\n",
        "import requests\n",
        "exec(requests.get(\"https://raw.githubusercontent.com/cytoscape/jupyter-bridge/master/client/p4c_init.py\").text)\n",
        "IPython.display.Javascript(_PY4CYTOSCAPE_BROWSER_CLIENT_JS) # Start browser client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPYfiaxkTXu5",
        "outputId": "40f53970-82d7-47b3-c6d6-2ba4db745dc7"
      },
      "outputs": [],
      "source": [
        "p4c.cytoscape_version_info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.B: Select CSV file containing network structure information\n",
        "#### File must be named \"Network_map.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "GvqAU-xMvnBX",
        "outputId": "8b09e1f4-48a6-4d7e-a10f-66bd143ab570"
      },
      "outputs": [],
      "source": [
        "# Import Network map data from csv\n",
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "nmap_csv = files.upload()\n",
        "edge_data = pd.read_csv(io.BytesIO(nmap_csv['Network_map.csv'])).dropna(how='all')\n",
        "edge_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.C: Select CSV file containing endpoint data\n",
        "#### File must be named \"Endpoint_data.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "YsIgoeON1X9c",
        "outputId": "61708028-77f4-4106-82f8-1e5ec4fdddbe"
      },
      "outputs": [],
      "source": [
        "# Import Enpoint data csv\n",
        "csvfile = files.upload()\n",
        "original_data = pd.read_csv(io.BytesIO(csvfile['Endpoint_data.csv'])).dropna(how='all')\n",
        "for col in original_data.columns[3:]:\n",
        "    original_data[col] = pd.to_numeric(original_data[col], errors='coerce')\n",
        "\n",
        "## Imputes any string values within each endpoint\n",
        "# Count endpoints variable\n",
        "num_columns = original_data.shape[1]\n",
        "# Temp data object for Group_2 endpoint values only\n",
        "Group_2_fill = original_data[original_data.iloc[:,2] == \"Group_2\"]\n",
        "# Temp data object for Group_1 endpoint values only\n",
        "Group_1_fill = original_data[original_data.iloc[:,2] == \"Group_1\"]\n",
        "# Iterate through endpoint columns and imputes string values for minimum value of tissue type divided by 2\n",
        "for i in range(3,num_columns):\n",
        "    # Selects minimum value for Group_2 data within endpoint data\n",
        "    min_val_t = Group_2_fill.iloc[:,i].min()\n",
        "    # Imputes strings for Group_2 values within endpoint data\n",
        "    Group_2_fill.iloc[:, i].fillna(min_val_t / 2, inplace=True)\n",
        "    # Selects minimum value for Group_1 data within endpoint data\n",
        "    min_val_s = Group_1_fill.iloc[:,i].min()\n",
        "    # Imputes strings for Group_1 values within endpoint data\n",
        "    Group_1_fill.iloc[:, i].fillna(min_val_t / 2, inplace=True)\n",
        "# Updates original dataframe\n",
        "original_data.update(Group_2_fill)\n",
        "original_data.update(Group_1_fill)\n",
        "\n",
        "original_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1UZKESzO2gN9",
        "outputId": "76b09fab-07b8-4f18-90c9-d5cbd65b48b1"
      },
      "outputs": [],
      "source": [
        "# Compare Group_2 to Group_1\n",
        "## Determine if data is parametric or not\n",
        "# Seed random number generator\n",
        "seed(1)\n",
        "# Alpha value for p-value significance\n",
        "alpha = 0.05\n",
        "# Count endpoints variable\n",
        "num_columns = original_data.shape[1]\n",
        "# List of endpoints with results\n",
        "e_list = []\n",
        "# List of p-value results\n",
        "p_list = []\n",
        "# List of Group_2 means\n",
        "t_means = []\n",
        "# List of Group_2 sd\n",
        "t_sds = []\n",
        "# List of Group_2 cv\n",
        "t_cvs = []\n",
        "# List of Group_1 means\n",
        "s_means = []\n",
        "# List of Group_1 sd\n",
        "s_sds = []\n",
        "# List of Group_1 cv\n",
        "s_cvs = []\n",
        "# List of significant or not\n",
        "sign_list = []\n",
        "for i in range(3,num_columns):\n",
        "    # Endpoint value column variable\n",
        "    endpoint = original_data.iloc[:,i]\n",
        "    # Targets endpoint value column name\n",
        "    e_name = original_data.iloc[:,i].name\n",
        "    print(e_name)\n",
        "    # Normality test (Shapiro-Wilk Test)\n",
        "    stat, p_value = shapiro(endpoint)\n",
        "    # Select only Group_2 data\n",
        "    Group_2 = original_data[original_data.iloc[:,2] == \"Group_2\"].iloc[:,i]\n",
        "    # Group_2 mean\n",
        "    Group_2_mean = Group_2.mean()\n",
        "    t_means.append(Group_2_mean)\n",
        "    # Group_2 stdev\n",
        "    Group_2_stdev = Group_2.std()\n",
        "    t_sds.append(Group_2_stdev)\n",
        "    # Group_2 cv\n",
        "    Group_2_cv = (Group_2_stdev / Group_2_mean) * 100\n",
        "    t_cvs.append(Group_2_cv)\n",
        "    # Select only Group_1 data\n",
        "    Group_1 = original_data[original_data.iloc[:,2] == \"Group_1\"].iloc[:,i]\n",
        "    # Group_1 mean\n",
        "    Group_1_mean = Group_1.mean()\n",
        "    s_means.append(Group_1_mean)\n",
        "    # Group_1 stdev\n",
        "    Group_1_stdev = Group_1.std()\n",
        "    s_sds.append(Group_1_stdev)\n",
        "    # Group_1 cv\n",
        "    Group_1_cv = (Group_1_stdev / Group_1_mean) * 100\n",
        "    s_cvs.append(Group_1_cv)\n",
        "    ## Action loop for p-value result\n",
        "    # If parametric, calculates Pearson correlation coefficient\n",
        "    if p_value > alpha:\n",
        "        # Print result of parametric test\n",
        "        print(\"Parametric, fail to reject H0\")\n",
        "        # Run Pearson correlation coefficient function\n",
        "        stat2, p_value2 = stats.pearsonr(Group_2,Group_1)\n",
        "        # Add endpoint that had values used to list\n",
        "        e_list.append(e_name)\n",
        "        # Add p-value result to list\n",
        "        p_list.append(p_value2)\n",
        "        # Interprets if endpoint is significant\n",
        "        if p_value2 < alpha:\n",
        "            # Prints result\n",
        "            print(\"Reject the null hypothesis: Correlation between samples is statistically significant.\")\n",
        "            # Add significance to list\n",
        "            sign_list.append(\"Yes\")\n",
        "        else:\n",
        "            # Prints result\n",
        "            print(\"Fail to reject the null hypothesis: Correlation between samples not is statistically significant.\")\n",
        "            # Add non-significance to list\n",
        "            sign_list.append(\"No\")\n",
        "    # If nonparametric, calculates Spearman rank-order correlation coefficient\n",
        "    else:\n",
        "        # Print result of parametric test\n",
        "        print(\"Nonparametric, reject H0\")\n",
        "        # Run Spearman rank-order correlation coefficient function\n",
        "        stat2, p_value2 = stats.spearmanr(Group_2,Group_1,nan_policy='omit')\n",
        "        # Add endpoint that had values used to list\n",
        "        e_list.append(e_name)\n",
        "        # Add p-value result to list\n",
        "        p_list.append(p_value2)\n",
        "        # Interprets if endpoint is significant\n",
        "        if p_value2 < alpha:\n",
        "            # Prints result\n",
        "            print(\"Reject null hypothesis: Correlation between samples is statistically significant.\")\n",
        "            # Add significance to list\n",
        "            sign_list.append(\"Yes\")\n",
        "        else:\n",
        "            # Prints result\n",
        "            print(\"Fail to reject null hypothesis: Correlation between samples not is statistically significant.\")\n",
        "            # Add non-significance to list\n",
        "            sign_list.append(\"No\")\n",
        "# Makes dictionary of endpoints and results\n",
        "d = {'endpoints':e_list,\n",
        "     'p_values':p_list,\n",
        "     'Group_2_means':t_means,\n",
        "     'Group_2_stdev':t_sds,\n",
        "     'Group_2_cv':t_cvs,\n",
        "     'Group_1_means':s_means,\n",
        "     'Group_1_stdev':s_sds,\n",
        "     'Group_1_cv':s_cvs,\n",
        "     'significant':sign_list\n",
        "     }\n",
        "# Takes dictionary and creates dataframe\n",
        "end_and_pvalues = pd.DataFrame(data=d)\n",
        "# Shows dataframe\n",
        "end_and_pvalues.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "riQkIANx2lsD",
        "outputId": "2a6e29d1-b811-4d61-98b4-e5fcdb6bcbac"
      },
      "outputs": [],
      "source": [
        "# Calculate deltas of Group_2 means compared to Group_1 for significant enpoints\n",
        "endpoints = []\n",
        "values = []\n",
        "significant = end_and_pvalues[end_and_pvalues[\"significant\"] == \"Yes\"]\n",
        "for index, row in significant.iterrows():\n",
        "    endpoints.append(row['endpoints'])\n",
        "    value = row['Group_2_means'] - row['Group_1_means']\n",
        "    values.append(value)\n",
        "delta_mean = {'id':endpoints, 'Endpoint':values}\n",
        "# Create dataframe from delta means of significant endpoints\n",
        "nodes = pd.DataFrame.from_dict(data=delta_mean,orient='columns')\n",
        "nodes.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "npA8Pd3N2oYl",
        "outputId": "298bebd2-0ca3-4eef-8147-057ea80e7e37"
      },
      "outputs": [],
      "source": [
        "# Create dataframe for network interactions\n",
        "topography = {'source':edge_data.iloc[:,0],\n",
        "             'target':edge_data.iloc[:,1]\n",
        "            }\n",
        "edges = pd.DataFrame(data=topography, columns=['source', 'target'])\n",
        "edges.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buK3Wxl82rZs",
        "outputId": "7a38319f-0640-4457-81e1-1f22e9e437db"
      },
      "outputs": [],
      "source": [
        "# Use network interaction dataframe to create network\n",
        "p4c.create_network_from_data_frames(edges=edges, title='Significant Endpoints network', collection=\"rppa collection\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hqHsy52C20L2",
        "outputId": "383fa23e-7598-4e7b-cddb-9640f15ea161"
      },
      "outputs": [],
      "source": [
        "# Loads endpoint data values to node table in cytoscape\n",
        "p4c.load_table_data(nodes, data_key_column='id', table='node', table_key_column='name')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kObjlcgd29hH",
        "outputId": "d1e7f50f-1333-4ea2-8b9d-f82a91c17d1c"
      },
      "outputs": [],
      "source": [
        "# Set nodes' default color to grey\n",
        "# Grey nodes for no data or non-significant endpoints\n",
        "from py4cytoscape import palette_color_brewer_d_RdBu\n",
        "p4c.set_visual_property_default({'visualProperty': 'NODE_FILL_COLOR', 'value': 'lightgrey'})\n",
        "# Apply color gradient to nodes corresponding to endpoint value\n",
        "p4c.set_node_color_mapping(**p4c.gen_node_color_map('Endpoint', palette_color_brewer_d_RdBu(),mapping_type='c'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ndj5mgmu3Eaz",
        "outputId": "a9143a41-53cb-4a7f-f4ee-38a4b4aec5ba"
      },
      "outputs": [],
      "source": [
        "# Analyze network, generate network values, and apply network values to node and edge tables\n",
        "p4c.analyze_network()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VIJbA_Xe3HbG",
        "outputId": "02045027-c736-44f8-aa3f-2ca9f75ea1aa"
      },
      "outputs": [],
      "source": [
        "# Export network image to jupyter notebook\n",
        "p4c.notebook_export_show_image()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Create legend\n",
        "### 3.A Go to the Style tab\n",
        "### 3.B Click three horizontal lines button \n",
        "### 3.C Select \"Create Legend\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
